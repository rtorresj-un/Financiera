---
title: "Parcial 3 - Econometría Financiera"
subtitle: "Raúl Esteban Torres Jiménez & Juanita Cortés Arroyo"
output: 
  pdf_document: 
    latex_engine: xelatex
---

```{r, include=FALSE}
library(quantmod); library(PerformanceAnalytics); library(rugarch); library(dplyr)
library(ggplot2); library(ggfortify); library(quantmod); library(gridExtra); library(forecast); library(cowplot); library(urca); library(timeDate); library(TSstudio); library(fBasics); library(randtests); library(vrtest); library(texreg); library(fGarch)
library(xts);library(zoo); library(TTR);library(tidyverse);library(dplyr); library(stats); library(greybox); library(smooth);library(PerformanceAnalytics); library(rugarch); library(tseries)

extract.rugarch <- function(fit, indep, 
                            include.rsquared = TRUE, include.loglike = TRUE, include.aic = TRUE, include.bic = TRUE) {

  # extract coefficient table from fit:
  coefnames <- rownames(as.data.frame(fit@fit$coef))
  coefs <- fit@fit$coef
  se <- as.vector(fit@fit$matcoef[, c(2)])
  pvalues <-  as.vector(fit@fit$matcoef[, c(4)])       # numeric vector with p-values

  # create empty GOF vectors and subsequently add GOF statistics from model:
  gof <- numeric()
  gof.names <- character()
  gof.decimal <- logical()
  if (include.rsquared == TRUE) {
    r2 <-  1 - (var(fit@fit$residuals) / var(indep))
    gof <- c(gof, r2)
    gof.names <- c(gof.names, "R^2")
    gof.decimal <- c(gof.decimal, TRUE)
  }
  if (include.loglike == TRUE) {
    loglike <- fit@fit$LLH
    gof <- c(gof, loglike)
    gof.names <- c(gof.names, "Log likelihood")
    gof.decimal <- c(gof.decimal, TRUE)
  }
  if (include.aic == TRUE) {
    aic <- infocriteria(fit)[c(1)]
    gof <- c(gof, aic)
    gof.names <- c(gof.names, "AIC")
    gof.decimal <- c(gof.decimal, TRUE)
  }

  if (include.bic == TRUE) {
    bic <- infocriteria(fit)[c(2)]
    gof <- c(gof, bic)
    gof.names <- c(gof.names, "BIC")
    gof.decimal <- c(gof.decimal, TRUE)
  }

  # create texreg object:
  tr <- createTexreg(
    coef.names = coefnames, 
    coef = coefs,
    se = se,
    pvalues = pvalues, 
    gof.names = gof.names, 
    gof = gof, 
    gof.decimal = gof.decimal
  )
  return(tr)
}


getSymbols('USDJPY=X',from = "2005-01-01", to = "2021-08-31", periodicity = "daily")
jp <-Cl(`USDJPY=X`)

jp_r <- data.frame(apply(jp, 2, function(x) Delt(x, type = "log")), fecha = index(jp))
jp_r<-na.omit(jp_r)
jp_r<-xts(jp_r[,1], order.by = jp_r$fecha)
```

Supongan que ustedes son analistas del mercado financiero en una entidad privada que invierte en Bolsa. Con el fin de guiar su política de inversión, la mesa de dinero requiere un análisis del comportamiento de la tasa de cambio del dólar americano USD frente al yen japones. En consecuencia, le piden que realice un análisis incluyendo datos diarios desde enero de 2005 y hasta agosto del 2021 el cual debe dar cuenta de:

  a. Estadística descriptiva (Además de otros análisis calcule la desviación estándar anualizada para los años de crisis (2008 y 2009), también la del año 2020 y comparela con la de la muestra completa.)
  
Se presenta la gráfica de la tasa de cambio del dolar americado \textbf{USD} frente al Yen japones \textbf{JPY}

```{r echo=FALSE ,message=FALSE ,fig.height = 2, fig.width = 5, fig.align = "center", fig.pos='h'}
knitr::opts_chunk$set(fig.width=4) 
ggplot(data = jp, aes(y = jp, x = index(jp))) + geom_line()+
  ggtitle("Tasa de cambio USD/JPY")+ 
  labs(x = "Fecha",y = "USD/JPY") +
  theme_minimal()
```
La serie de la tasa de cambio no presenta una tendencia clara, sin embargo, presenta alta persistencia en el tiempo por tanto no es estacionaria
```{r echo=FALSE, fig.height = 2, fig.width = 5, fig.align = "center", warning = FALSE,fig.pos='h',message=FALSE}
grid.arrange(
ggAcf(jp,52)+ggtitle("USD/JPY")+labs(x="")+theme_minimal()+theme_minimal()
#,ggPacf(jp,52)+ggtitle("")
)
```
Se observa que los retornos fluctuan al rededor de cero, son volátiles y presentan clusters de volatilidad, lo que concuerda con el comportamiento esperado de los retornos de las series finacieras.Además, los datos están altamente concentrados al rededor de su valor medio y se encuentra una mayor probabilidad de datos atípicos (representados en las colas), lo que hace que la distribución de los retornos sea leptocúrtica y tenga colas pesadas.
```{r echo=FALSE, fig.height = 4, fig.width = 5, fig.align = "center", message=FALSE,fig.pos='h'}
# plot retornos diarios 
grid.arrange(
ggplot(data = jp_r, aes(y = jp_r[,1], x = index(jp_r))) + geom_line()+ggtitle("Retornos diarios USD/JPY")+ labs(x = "Fecha",y = "") + theme_minimal(),
ggplot(data = jp_r, aes(y=..density.., x = jp_r[,1])) +
  geom_histogram(bins = 200) +
  ggtitle("Distrubución retornos diarios") +
  geom_vline(aes(xintercept=mean(jp_r)), linetype="dashed") +
  geom_density(alpha=.2, fill="lightblue") + labs(x='',y='') +theme_minimal()
)
```
Con el gráfico de autocorrelación simple no se puede determinar si los retornos son estacionarios pues presenta rezagos significativos, sin embargo, al realizar la prueba DF se determina que la serie es estacionaria 
```{r echo=FALSE, fig.align="center", fig.height=5, fig.pos='h', fig.width=5, message=FALSE, warning=FALSE}
grid.arrange(
ggAcf(jp_r,52)+ggtitle("Retornos diarios")+labs(x="")+theme_minimal()+theme_minimal()
#,ggPacf(jp_r,52)+ggtitle("")
)

adf.test(jp_r)


#No necesidad de modelar la media del proceso.
```
El valor de la desviación estándar es más alto al de la media, por lo que la volatidad domina la dinámica de los retornos y la distribución es negativamente asimétrica.
```{r echo=FALSE, caption='Estadística descriptiva.', warning = FALSE,fig.pos='h',message=FALSE}
stats_d<-basicStats(jp_r[,1])[c("Mean", "Stdev", "Minimum", "Maximum", "Variance","Skewness","Kurtosis"),]

#En tabla: 
stats<-data.frame(stats_d)
row.names(stats)<-c("Mean", "SD", "Minimum", "Maximum", "Variance","Skewness","Kurtosis")
colnames(stats)<-c('USD/JPY')
knitr::kable(stats)
```

Los retornos al cuadrado como proxy de la volatilidad, se observan picos tras la crisis financiera del 2008 
```{r echo=FALSE, fig.height = 4, fig.width = 5, fig.align = "center", warning = FALSE,fig.pos='h',message=FALSE}
#retornos ^2 distribucion y grafico
grid.arrange(
ggplot(data = jp_r, aes(y = jp_r^2, x = index(jp_r))) + 
  geom_line() +
  ggtitle("Volatilidad retornos USD/JPY") + 
  labs(x = "Fecha",y = "") + theme_minimal(),
ggplot(data = jp_r, aes(y=..density.., x = jp_r^2)) +
  geom_histogram(bins = 200) +
  ggtitle("Distrubución volatilidad retornos diarios") +
  geom_vline(aes(xintercept=mean(jp_r)), linetype="dashed") +
  geom_density(alpha=.2, fill="lightblue") + labs(x='',y='') + theme_minimal()
)
```


```{r echo=FALSE}
#calcule la desviación estándar anualizada para los años de crisis (2008 y 2009), también la del año 2020 y comparela con la de la muestra completa 
#chart.RollingPerformance(ret, width = 22, FUN = "sd.annualized", scale = 252, main = "One month rolling volatility")
# series ret de los años y aplicar la funcion 
```

```{r echo=FALSE, fig.height = 7, fig.width = 7, fig.align = "center", warning = FALSE,fig.pos='h',message=FALSE}
#chart.TimeSeries(jp)
jp_r08<-window(jp_r, start='2008-01-21', end='2009-12-31')
jp_r20<-window(jp_r, start='2020-01-01', end=Sys.Date())
#rollapply(jp_r)
par(mfrow=c(3,1))
chart.RollingPerformance(jp_r08, width = 22, FUN = "sd.annualized", scale = 252, main = "Volatilidad anualizada 2008-2009")
chart.RollingPerformance(jp_r20, width = 22, FUN = "sd.annualized", scale = 252, main = "Volatilidad anualizada 2020-2021")
chart.RollingPerformance(jp_r, width = 22, FUN = "sd.annualized", scale = 252, main = "Volatilidad anualizada total")

#Se observan clústeres de volatilidad, media que no es cero ni varianza constante => modelar volatilidad.
```

  b. Modelación de la media condicional. ¿Es la media condicional igual a cero?
```{r echo=FALSE,fig.pos='h',fig.height = 3, fig.width = 7, fig.align = "center", fig.show='hide'}
# media incondicional 
#dataSMA.EMA=merge.xts('Retornos'=jp_r, 'Media móvil simple'= SMA(jp_r), 'Media móvil exponencial'= EMA(jp_r), fill = 'NA')
#ggplot(data = dataSMA.EMA, aes(x = index(dataSMA.EMA))) + 
#  geom_line(aes(y= Retornos, color='Retornos')) +
#  geom_line(aes(y= SMA, color='SMA')) +
#  geom_line(aes(y= EMA, color='EMA')) +
#  labs(x = "Fecha",y = "", color = "") + theme_minimal()
#chart.TimeSeries(dataSMA.EMA, lwd = 1, legend.loc = "topright", colorset = #c('grey',"darkgreen","firebrick"))
#lines(SMA(Cl(na.omit(jp)), n = 200), col = "darkgreen")
#lines(EMA(Cl(na.omit(jp)), n = 200), col = "firebrick")

# media incondicional
plot(na.omit(jp), main= "Media movil y exponencial USD/JPY", legend=TRUE)
lines(SMA(Cl(na.omit(jp)), n = 200), col = "darkgreen")
#Observar si hay un proceso de autocorrelación, si la media es cero, la varianza constante, etc.
```
```{r echo=FALSE,fig.pos='h',fig.height = 3, fig.width = 7, fig.align = "center"}
lines(EMA(Cl(na.omit(jp)), n = 200), col = "firebrick")
#legend("topright", legend = c("Retornos", "SMA", "EMA"), col = c("black", "darkgreen", "firebrick"), lwd = 2, text.font = i)
```


```{r echo= FALSE, fig.height = 3, fig.width = 7, fig.align = "center", warning = FALSE,fig.pos='h',fig.show= 'hide'}
# medias moviles retornos
plot(jp_r, main= "Media movil y exponencial de retornos USD/JPY")
lines(SMA(jp_r, n = 100), col = "darkgreen")
#Observar si hay un proceso de autocorrelación, si la media es cero, la varianza constante, etc.
```
```{r echo=FALSE,fig.pos='h',fig.height = 3, fig.width = 7, fig.align = "center"}
lines(EMA(jp_r, n = 100), col = "firebrick")
```

  c. Modelación de la varianza condicional (verifique la existencia de efecto leverage o asimetrías comparando diferentes especificaciones usando criterios de información). ¿Cuál es el modelo que mejor se ajusta al proceso de volatilidad de la tasa de cambio?
  


```{r echo=FALSE, fig.height = 5, fig.width = 5, fig.align = "center", warning = FALSE,fig.pos='h',message=FALSE}
grid.arrange(
ggAcf(jp_r^2,52)+ggtitle("Volatilidad retornos diarios")+labs(x="")+theme_minimal(),
ggPacf(jp_r^2,52)+ggtitle("")+theme_minimal()
)
#Necesidad de modelar la varianza.
```

```{r echo=FALSE ,message=FALSE, results = 'asis',fig.pos='h'}
garch11.spec = ugarchspec(variance.model = list(garchOrder=c(1,1)),
                          mean.model = list(armaOrder=c(0,0)))
garch11.fit = ugarchfit(spec=garch11.spec, data=jp_r)

texreg(extract.rugarch(garch11.fit, indep = jp_r, include.rsquared = FALSE), digits = 8, custom.coef.names = c("mu", "omega", "alpha", "beta"), caption = "Resultados del modelo", custom.model.names = "sGARH(1,1)") #for latex # as R^2 is zero in this example.

```

```{r, echo=FALSE,fig.pos='h'}
knitr::kable(signbias(garch11.fit)[,c(2,3)])
```
```{r, echo=FALSE,fig.pos='h'}
nybtab11<-nyblom(garch11.fit)$IndividualStat
colnames(nybtab11)<-c("p-value")
knitr::kable(nybtab11)

nybtab11c<-data.frame(nyblom(garch11.fit)$IndividualCritical)
colnames(nybtab11c)<-c("Valores críticos")
knitr::kable(nybtab11c)
```

Se observa alpha y beta significativos, dan cuenta  de clustering y persistencia.
mu no es significativo, su media es cero.
omega es la constante de la volatilidad, ie, media de largo plazo de la volatilidad del proceso. No significativa.
alpha+beta es casi 1; es un modelo estacionario.
alpha es sesnibilidad a la llegada de información y beta es persistencia de la volatilidad.
Nyblom: hay cambio estructural en mu, alpha y beta. No en omega.
Leverage: no hay conjunto, hay sesgo solamente negativo.
Comparar por bondad de ajuste y criterios de información.

```{r echo=FALSE ,message=FALSE, results = 'asis',fig.pos='h'}
garch11.spec = ugarchspec(variance.model = list(garchOrder=c(1,1)),
                          mean.model = list(armaOrder=c(0,0)))
garch11.fit = ugarchfit(spec=garch11.spec, data=jp_r)

texreg(extract.rugarch(garch11.fit, indep = jp_r, include.rsquared = FALSE), digits = 8, custom.coef.names = c("mu", "omega", "alpha", "beta"), caption = "Resultados del modelo", custom.model.names = "sGARCH(1,1)") #for latex # as R^2 is zero in this example.
```

```{r}
#plot(garch11.fit, which="all")
resid1<-residuals(garch11.fit)
med<-mean(resid1)
normaldens<-data.frame(predicted = resid1, density = dnorm(resid1, mean(resid1), sd(resid1)))
resid1<-residuals(garch11.fit, standardize=T)

grid.arrange(
ggplot(data= as.data.frame(resid1), aes(y =as.data.frame(resid1)[,1], x = index(jp_r))) + geom_line()+ggtitle("Residuos del modelo GARCH(1,1)")+ labs(x = "Fecha",y = "") + theme_minimal(),
ggAcf(resid1,52)+ggtitle("")+labs(x="")+theme_minimal(),
ggplot(data = as.data.frame(resid1), aes(y=..density.., x = jp_r[,1])) +
  geom_histogram(bins = 200) +
  ggtitle("") +
  geom_vline(aes(xintercept=med), linetype="dashed") +
  geom_density(alpha=.2, fill="steelblue") + labs(x='',y='') +
  geom_line(aes(y = density), data = normaldens, colour = "firebrick") + theme_minimal(),
ggPacf(resid1,52)+ggtitle("")+theme_minimal()
)

```

```{r}
		ni = newsimpact(z = NULL, garch11.fit)
		ni.y = ni$zy
		ni.x = ni$zx
		xf = ni$xexpr
		yf  = ni$yexpr
		ggplot(data = data.frame(ni.y,ni.x), aes(x=ni.x,y=ni.y))+
		  geom_line(colour="steelblue") + xlab(xf) + ylab(yf) + theme_minimal()
#		plot( ni.x, ni.y, ylab = yf, xlab = xf, type = "l", lwd = 2, col = "steelblue", main = "News Impact Curve", cex.main = 0.8)
```

```{r echo=FALSE ,message=FALSE, results = 'asis',fig.pos='h'}
garch11sstd.spec = ugarchspec(variance.model = list(garchOrder=c(1,1)),
                          mean.model = list(armaOrder=c(0,0)),
                          distribution.model = "sstd")
garch11sstd.fit = ugarchfit(spec=garch11sstd.spec, data=jp_r)

texreg(extract.rugarch(garch11sstd.fit, indep = jp_r, include.rsquared = FALSE), digits = 8, custom.coef.names = c("mu", "omega", "alpha", "beta", "skew", "shape"), caption = "Resultados del modelo", custom.model.names = "sGARCH(1,1)~sstd") #for latex # as R^2 is zero in this example.
```

```{r echo=FALSE}
#plot(garch11sstd.fit, which="all")
resid2<-residuals(garch11sstd.fit)
med<-mean(resid2)
sstddens1<-data.frame(predicted = resid2, density = dsstd(resid2, mean(resid2), sd(resid2), xi = garch11sstd.fit@fit[["coef"]][["skew"]]))
resid2<-residuals(garch11sstd.fit, standardize=T)

grid.arrange(
ggplot(data= as.data.frame(resid2), aes(y =as.data.frame(resid2)[,1], x = index(jp_r))) + geom_line()+ggtitle("Residuos del modelo GARCH(1,1)~sstd")+ labs(x = "Fecha",y = "") + theme_minimal(),
ggAcf(resid2,52)+ggtitle("")+labs(x="")+theme_minimal(),
ggplot(data = as.data.frame(resid2), aes(y=..density.., x = jp_r[,1])) +
  geom_histogram(bins = 200) +
  ggtitle("") +
  geom_vline(aes(xintercept=med), linetype="dashed") +
  geom_density(alpha=.2, fill="steelblue") + labs(x='',y='') +
  geom_line(aes(y = density), data = sstddens1, colour = "firebrick") + theme_minimal(),
ggPacf(resid2,52)+ggtitle("")+theme_minimal()
)
```

```{r echo=FALSE ,message=FALSE, results = 'asis',fig.pos='h'}
gjrgarch11.spec = ugarchspec(variance.model = list(model="gjrGARCH", garchOrder=c(1,1)),
                          mean.model = list(armaOrder=c(0,0)),
                          distribution.model = "sstd")
gjrgarch11.fit = ugarchfit(spec=gjrgarch11.spec, data=jp_r)

texreg(extract.rugarch(gjrgarch11.fit, indep = jp_r, include.rsquared = FALSE), digits = 8, custom.coef.names = c("mu", "omega", "alpha", "beta", "gamma", "skew", "shape"), caption = "Resultados del modelo", custom.model.names = "GJR-GARCH(1,1)~sstd") #for latex # as R^2 is zero in this example.
```

```{r}
resid3<-residuals(gjrgarch11.fit)
med<-mean(resid3)
sstddens2<-data.frame(predicted = resid3, density = dsstd(resid3, mean(resid3), sd(resid3), xi = gjrgarch11.fit@fit[["coef"]][["skew"]]))
resid3<-residuals(gjrgarch11.fit, standardize=T)

params<-as.list(c(mean(resid3), sd(resid3), xi = gjrgarch11.fit@fit[["coef"]][["skew"]]))

grid.arrange(
ggplot(data= as.data.frame(resid3), aes(y =as.data.frame(resid3)[,1], x = index(jp_r))) + geom_line()+ggtitle("Residuos del modelo GJR-GARCH(1,1)~sstd")+ labs(x = "Fecha",y = "") + theme_minimal(),
ggAcf(resid3,52)+ggtitle("")+labs(x="")+theme_minimal(),
ggplot(data = as.data.frame(resid3), aes(y=..density.., x = jp_r[,1])) +
  geom_histogram(bins = 200) +
  ggtitle("") +
  geom_vline(aes(xintercept=med), linetype="dashed") +
  geom_density(alpha=.2, fill="steelblue") + labs(x='',y='') +
  geom_line(aes(y = density), data = sstddens2, colour = "firebrick") + theme_minimal(),
ggplot(data= as.data.frame(resid3), aes(sample = as.data.frame(resid3)[,1])) +
stat_qq(distribution = qsstd, dparams = params) + stat_qq_line(distribution = qsstd, dparams = params, colour="firebrick") + labs(x="",y="") + theme_minimal()
)
```

```{r}
ni_r = newsimpact(z = NULL, gjrgarch11.fit)
		ni.y_r = ni_r$zy
		ni.x_r = ni_r$zx
		xf = ni_r$xexpr
		yf  = ni_r$yexpr
		ggplot(data = data.frame(ni.y_r,ni.x_r, ni.x, ni.y))+
		  geom_line(aes(x=ni.x,y=ni.y, colour="GARCH(1,1)"), color="steelblue") +
		  geom_line(aes(x=ni.x_r,y=ni.y_r, colour="GJR-GARCH(1,1)"), color="firebrick") + 
		  xlab(xf) + ylab(yf) + theme_minimal()
#		plot( ni.x, ni.y, ylab = yf, xlab = xf, type = "l", lwd = 2, col = "steelblue", main = "News Impact Curve", cex.main = 0.8)
```


  d. Pronóstico de la volatilidad a 10 días.

  e. Cuál es la probabilidad de tener pérdidas con el 99% de confianza en un horizonte de día (use los resultados de su modelación para el cálculo).
  
```{r echo= FALSE,message=FALSE}
# asuminedo distribucion normal
mu_R<- mean(jp_r)
sigma_R<- sd(jp_r)
W0<- 100000
W0*qnorm(0.01, mean= mu_R, sd<- sigma_R)
```
  
  f. ¿Cambió la pandemia del COVID-19 la estructura de la volatilidad de la tasa de cambio? (para eso use datos desde enero del 2018).
  

Nota: Se espera que cada grupo ELIJA UNA TASA DE CAMBIO DIFERENTE, y presente un informe ejecutivo de no más de 10 páginas, en el que de respuesta a cada pregunta y presente los argumentos empíricos necesarios que la sustenten. Explique sus resultados e interprételos.

